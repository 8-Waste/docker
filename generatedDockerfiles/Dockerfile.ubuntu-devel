#
# This file was generated! Edits made directly to this file may be lost.
#   Timestamp:    2019-08-02
#
# RAPIDS Dockerfile for Ubuntu
#
# This multi-stage Dockerfile is used to create the "devel" image.
#
# RAPIDS is built from-source and installed in the 'rapids' conda
# environment. The sources and toolchains to build RAPIDS are included in this
# image. RAPIDS jupyter notebooks are also provided, as well as jupyterlab and
# all the dependencies required to run them.
#
# Copyright (c) 2019, NVIDIA CORPORATION.

ARG CUDA_TYPE=devel
ARG CUDA_VERSION=10.0
ARG CUDA_MAJORMINOR_VERSION=${CUDA_VERSION}
ARG LINUX_VERSION=ubuntu18.04
ARG PYTHON_VERSION=3.7

FROM gpuci/rapidsai-minicuda:${CUDA_VERSION}-${CUDA_TYPE}-${LINUX_VERSION}-py${PYTHON_VERSION}

ARG CC_VERSION
ARG CXX_VERSION
ARG CUDA_VERSION
ARG CUDA_MAJORMINOR_VERSION

ARG CC_VERSION=7
ARG CXX_VERSION=7
ARG DASK_VERSION=">2"
ARG DASK_XGBOOST_CONDA_VERSION_SPEC=0.2*
ARG DISTRIBUTED_VERSION=">2"
ARG FAISSGPU_VERSION=1.5.0
ARG HASH_JOIN=ON
ARG IPYTHON_VERSION=7.3*
ARG NCCL_CONDA_VERSION=">2"
ARG NVIDIA_CONDA_LABEL=nvidia/label/cuda${CUDA_MAJORMINOR_VERSION}
ARG PYTHON_VERSION=3.6
ARG RAPIDSAI_CONDA_LABEL=rapidsai/label/cuda${CUDA_MAJORMINOR_VERSION}
ARG RAPIDS_CONDA_VERSION_SPEC=0.9*
ARG RAPIDSAI_NIGHTLY_CONDA_LABEL=rapidsai-nightly/label/cuda${CUDA_MAJORMINOR_VERSION}
ARG XGBOOST_CONDA_VERSION_SPEC=0.90*
ARG XGBOOST_CONDA_LABEL=rapidsai/label/xgboost
ARG XGBOOST_VERSION=0.90

ENV CC=/usr/bin/gcc-${CC_VERSION}
ENV CXX=/usr/bin/g++-${CXX_VERSION}
ENV CUDAHOSTCXX=$CXX
ENV CUDA_VERSION=${CUDA_MAJORMINOR_VERSION}
ENV RAPIDS_DIR=/rapids

# conda environment
# NOTE: use these mirrors for faster downloads
#       -c http://10.33.227.188:88/numba \
#       -c http://10.33.227.188:88/conda-forge \
RUN export CUDA_MAJOR=`echo $CUDA_VERSION | cut -d'.' -f1` && \
    export CUDA_MINOR=`echo $CUDA_VERSION | cut -d'.' -f2` && \
    conda install -n rapids -y \
      -c ${RAPIDSAI_CONDA_LABEL} \
      -c ${RAPIDSAI_NIGHTLY_CONDA_LABEL} \
      -c ${NVIDIA_CONDA_LABEL} \
      -c nvidia \
      -c numba \
      -c conda-forge \
      -c pytorch \
      -c defaults \
      arrow-cpp=0.14.1 \
      bokeh \
      cmake=3.14 \
      cmake_setuptools">=0.1.3" \
      cuda${CUDA_MAJOR}${CUDA_MINOR} \
      dask=${DASK_VERSION} \
      distributed=${DISTRIBUTED_VERSION} \
      double-conversion \
      dlpack \
      faiss-gpu=${FAISSGPU_VERSION} \
      flatbuffers \
      ipython=${IPYTHON_VERSION} \
      jupyterlab \
      libclang \
      liblapack \
      matplotlib \
      nccl=${NCCL_CONDA_VERSION} \
      networkx \
      openblas \
      pandas=0.24.2 \
      pyarrow=0.14.1 \
      rapidjson \
      seaborn \
      tensorflow \
    && conda clean -a

# Special case: libcumlmg is not available for CUDA 9.2
RUN if [ "${CUDA_MAJORMINOR_VERSION}" != "9.2" ]; then conda install -n rapids -y --no-deps -c ${NVIDIA_CONDA_LABEL} -c conda-forge libcumlmg; fi

# 'rapidsdevtool.sh buildDockerImage' sets up the build context, including the
#  rapids directory being COPY'd below. See rapidsdevtool.sh help for details.
RUN mkdir -p ${RAPIDS_DIR}
COPY rapids ${RAPIDS_DIR}
COPY utils ${RAPIDS_DIR}/utils
# Add test file for testing notebooks from within the container
COPY supportfiles/test.sh /test.sh

# clone.sh is generated by `rapidsdevtool.sh buildDockerImage` and is based on
# the URLs and branch names in the config file.
RUN cd ${RAPIDS_DIR} && ./clone.sh

# xgboost build will not find nccl in the conda env without this env var
ENV NCCL_ROOT=/conda/envs/rapids

# Assume the build.sh script is present.
# (this is done automatically when using 'rapidsdevtool.sh buildDockerImage',
#  see rapidsdevtool.sh help for more details)
RUN source activate rapids && cd ${RAPIDS_DIR}/rmm && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR}/custrings && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR}/cudf && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR}/cuml && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR}/cugraph && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh xgboost
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh dask-xgboost
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh dask-cuda

WORKDIR ${RAPIDS_DIR}/notebooks
# Jupyter notebook port
EXPOSE 8888
# Dask Scheduler Bokeh port
EXPOSE 8787
EXPOSE 8786

# Activate the rapids conda env for interactive shells via the default .bashrc
# The ENTRYPOINT script (see below) still sets the env, but this ensures the
# interactive settings (prompt) are set properly too.  root did not read
# /etc/bash.bashrc, so also add to /root/.bashrc
RUN echo "source activate rapids" >> /etc/bash.bashrc
RUN echo "source activate rapids" >> /root/.bashrc

# Create a dedicated startup env script that activates the rapids conda env for
# use with the non-interactive bash env var, to be set later. Then create a new
# script to exec the command (if given) in the environemnt set up by BASH_ENV
# and use it as the ENTRYPOINT.
RUN echo "source activate rapids" > /.activate_rapids
RUN chmod 777 /.activate_rapids
RUN echo "#!/bin/bash" > /.run_in_rapids_env
RUN echo "exec \"\$@\"" >> /.run_in_rapids_env
RUN chmod 777 /.run_in_rapids_env
ENTRYPOINT [ "/usr/bin/tini", "--", "/.run_in_rapids_env" ]

# Set the env startup script var for non-interactive shells
ENV BASH_ENV=/.activate_rapids

# Set the default command to pass to the ENTRYPOINT if no command was given
CMD [ "/bin/bash" ]

# Copy Dockerfile as late as possible to avoid invalidating cache for trivial changes
COPY Dockerfile.ubuntu-devel /Dockerfile.ubuntu-devel
