#
# This file was generated! Edits made directly to this file may be lost.
#   Timestamp:    2019-08-06
#
# RAPIDS Dockerfile for CentOS7
#
# This multi-stage Dockerfile is used to create the "devel" image.
#
# RAPIDS is built from-source and installed in the 'rapids' conda
# environment. The sources and toolchains to build RAPIDS are included in this
# image. RAPIDS jupyter notebooks are also provided, as well as jupyterlab and
# all the dependencies required to run them.
#
# Copyright (c) 2019, NVIDIA CORPORATION.

# These ARGs are used in multiple stages and must be defined prior to first FROM

ARG CUDA_TYPE=devel
ARG CUDA_VERSION=10.0
ARG CUDA_MAJORMINOR_VERSION=${CUDA_VERSION}
ARG LINUX_VERSION=centos7

FROM gpuci/miniconda-cuda:${CUDA_VERSION}-${CUDA_TYPE}-${LINUX_VERSION} AS base

ARG CUDA_VERSION
ARG CUDA_MAJORMINOR_VERSION
ARG GCC7_DIR=/usr/local/gcc7
ARG SUPPORT_FILES_DIR=supportfiles

ARG ARROW_CPP_VERSION=0.14.1
ARG CC_VERSION=7
ARG CFFI_VERSION=1.11.5
ARG CMAKE_VERSION=3.14
ARG CXX_VERSION=7
ARG CYTHON_VERSION=0.29.*
ARG DASK_VERSION=">2"
ARG DASK_XGBOOST_CONDA_VERSION_SPEC=0.2*
ARG DISTRIBUTED_VERSION=">2"
ARG FAISSGPU_VERSION=1.5.0
ARG HASH_JOIN=ON
ARG IPYTHON_VERSION=7.3*
ARG NCCL_CONDA_VERSION=">2"
ARG NUMBA_VERSION=0.41
ARG NUMPY_VERSION=1.16.2
ARG NVIDIA_CONDA_LABEL=nvidia/label/cuda${CUDA_MAJORMINOR_VERSION}
ARG PANDAS_VERSION=0.24.2
ARG PYTHON_VERSION=3.6
ARG PYARROW_VERSION=0.14.1
ARG RAPIDSAI_CONDA_LABEL=rapidsai/label/cuda${CUDA_MAJORMINOR_VERSION}
ARG RAPIDS_CONDA_VERSION_SPEC=0.9*
ARG RAPIDSAI_NIGHTLY_CONDA_LABEL=rapidsai-nightly/label/cuda${CUDA_MAJORMINOR_VERSION}
ARG XGBOOST_CONDA_VERSION_SPEC=0.90.rapidsdev1
ARG XGBOOST_CONDA_LABEL=rapidsai/label/xgboost
ARG XGBOOST_VERSION=0.90

ENV CUDA_VERSION=${CUDA_MAJORMINOR_VERSION}
ENV RAPIDS_DIR=/rapids

#
# The support dir contains RPMs that enable additional repos needed
# for CentOS (among other things). Copy them to a temp dir and remove
# after installed.
#
COPY ${SUPPORT_FILES_DIR}/*.rpm /tmp

RUN yum install -y /tmp/*.rpm && \
    rm -rf /tmp/*.rpm && \
    yum upgrade -y && \
    yum install -y \
      bzip2 \
      curl \
      git \
      screen \
      vim \
      wget \
      which \
      libnccl-2.4.2-1+cuda${CUDA_MAJORMINOR_VERSION} \
      libnccl-devel-2.4.2-1+cuda${CUDA_MAJORMINOR_VERSION} \
      libnccl-static-2.4.2-1+cuda${CUDA_MAJORMINOR_VERSION}

# Install gcc7 from prebuilt image
COPY --from=gpuci/builds-gcc7:10.0-devel-centos7 /usr/local/gcc7 /usr/local/gcc7

# Update environment to use new gcc7
ENV CC=${GCC7_DIR}/bin/gcc
ENV CXX=${GCC7_DIR}/bin/g++
ENV PATH=${GCC7_DIR}/bin:$PATH
ENV CUDAHOSTCXX=${GCC7_DIR}/bin/g++
ENV LD_LIBRARY_PATH=${GCC7_DIR}/lib64

# Update environment to use new gcc7
#ENV CC=${GCC7_DIR}/bin/gcc
#ENV CXX=${GCC7_DIR}/bin/g++
#ENV CUDAHOSTCXX=${GCC7_DIR}/bin/g++
#ENV LD_LIBRARY_PATH=${GCC7_DIR}/lib64:$CONDA_PREFIX:$LD_LIBRARY_PATH
#ENV NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so
#ENV NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice
#ENV PATH=$PATH:/conda/bin
#ENV PATH=${GCC7_DIR}/bin:$PATH
RUN export CUDA_MAJOR=`echo $CUDA_VERSION | cut -d'.' -f1` && \
    export CUDA_MINOR=`echo $CUDA_VERSION | cut -d'.' -f2` && \
    conda create -n rapids python=${PYTHON_VERSION} && \
    conda install -n rapids -y \
      -c ${RAPIDSAI_CONDA_LABEL} \
      -c ${RAPIDSAI_NIGHTLY_CONDA_LABEL} \
      -c ${NVIDIA_CONDA_LABEL} \
      -c nvidia \
      -c numba \
      -c conda-forge \
      -c pytorch \
      -c defaults \
      arrow-cpp=${PYARROW_VERSION} \
      bokeh \
      cffi=${CFFI_VERSION} \
      cmake=${CMAKE_VERSION} \
      cmake_setuptools">=0.1.3" \
      cuda${CUDA_MAJOR}${CUDA_MINOR} \
      cudatoolkit=${CUDA_MAJORMINOR_VERSION} \
      cython=${CYTHON_VERSION} \
      dask=${DASK_VERSION} \
      dask_labextension \
      distributed=${DISTRIBUTED_VERSION} \
      double-conversion \
      dlpack \
      faiss-gpu=${FAISSGPU_VERSION} \
      flatbuffers \
      ipython=${IPYTHON_VERSION} \
      jupyterlab \
      libclang \
      liblapack \
      make \
      matplotlib \
      nccl=${NCCL_CONDA_VERSION} \
      networkx \
      nodejs \
      numba=${NUMBA_VERSION} \
      numpy=${NUMPY_VERSION} \
      openblas \
      pandas=${PANDAS_VERSION} \
      pyarrow=${PYARROW_VERSION} \
      pytest \
      rapidjson \
      scikit-learn \
      scipy=${SCIPY_VERSION} \
      seaborn \
      tensorflow \
    && conda clean -afy

# Special case: libcumlmg is not available for CUDA 9.2
RUN if [ "${CUDA_MAJORMINOR_VERSION}" != "9.2" ]; then conda install -n rapids -y --no-deps -c ${NVIDIA_CONDA_LABEL} -c conda-forge libcumlmg; fi

# Allow non-root to modify conda
RUN chmod -R ugo+w /opt/conda

RUN source activate rapids && jupyter labextension install dask-labextension

# 'rapidsdevtool.sh buildDockerImage' sets up the build context, including the
#  rapids directory being COPY'd below. See rapidsdevtool.sh help for details.
RUN mkdir -p ${RAPIDS_DIR}
COPY rapids ${RAPIDS_DIR}
COPY utils ${RAPIDS_DIR}/utils
# Add test file for testing notebooks from within the container
COPY supportfiles/test.sh /test.sh

# clone.sh is generated by `rapidsdevtool.sh buildDockerImage` and is based on
# the URLs and branch names in the config file.
RUN cd ${RAPIDS_DIR} && ./clone.sh

# Add /usr/local/cuda/* temporarily to LD_LIBRARY_PATH to support various build steps
# This will need to be removed later since it causes problems with certain runtime libs (numba.cuda)
ENV LD_LIBRARY_PATH_PREBUILD=${LD_LIBRARY_PATH}
ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs

# xgboost build will not find nccl in the conda env without this env var
ENV NCCL_ROOT=/conda/envs/rapids

# Assume the build.sh script is present.
# (this is done automatically when using 'rapidsdevtool.sh buildDockerImage',
#  see rapidsdevtool.sh help for more details)
RUN source activate rapids && cd ${RAPIDS_DIR}/rmm && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR}/custrings && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR}/cudf && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR}/cuml && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR}/cugraph && \
    ./build.sh
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh xgboost
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh dask-xgboost
RUN source activate rapids && cd ${RAPIDS_DIR} && \
    ./build.sh dask-cuda

#
# Change LD_LIBRARY_PATH to exclude /usr/local/cuda/* since
# numba.cuda cannot load that, and instead have it load
# /lib64/libcuda.so instead
#
ENV LD_LIBRARY_PATH=${LD_LIBRARY_PATH_PREBUILD}

WORKDIR ${RAPIDS_DIR}/notebooks
# Jupyter notebook port
EXPOSE 8888
# Dask Scheduler Bokeh port
EXPOSE 8787
EXPOSE 8786

# Allow non-root to modify /rapids sources
RUN chmod -R ugo+w /rapids

# Activate the rapids conda env for interactive shells via the default .bashrc
# The ENTRYPOINT script (see below) still sets the env, but this ensures the
# interactive settings (prompt) are set properly too.  root did not read
# /etc/bash.bashrc, so also add to /root/.bashrc
RUN echo "source activate rapids" >> /etc/bash.bashrc
RUN echo "source activate rapids" >> /root/.bashrc

# Create a dedicated startup env script that activates the rapids conda env for
# use with the non-interactive bash env var, to be set later. Then create a new
# script to exec the command (if given) in the environemnt set up by BASH_ENV
# and use it as the ENTRYPOINT.
RUN echo "source activate rapids" > /.activate_rapids
RUN chmod 777 /.activate_rapids
RUN echo "#!/bin/bash" > /.run_in_rapids_env
RUN echo "exec \"\$@\"" >> /.run_in_rapids_env
RUN chmod 777 /.run_in_rapids_env
ENTRYPOINT [ "/usr/bin/tini", "--", "/.run_in_rapids_env" ]

# Set the env startup script var for non-interactive shells
ENV BASH_ENV=/.activate_rapids

# Set the default command to pass to the ENTRYPOINT if no command was given
CMD [ "/bin/bash" ]

# Copy Dockerfile as late as possible to avoid invalidating cache for trivial changes
COPY Dockerfile.centos7-devel /Dockerfile.centos7-devel
