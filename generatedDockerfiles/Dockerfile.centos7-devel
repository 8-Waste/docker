#
# This file was generated! Edits made directly to this file may be lost.
#   Generator:    /home/nfs/rratzel/Projects/build/commands/../commands/utils/genfile.sh
#   Timestamp:    Fri May 17 15:30:35 PDT 2019
#   Template Dir: /home/nfs/rratzel/Projects/build/templates/docker
#
ARG CUDA_VERSION=10.0
ARG CUDA_MAJORMINOR_VERSION=${CUDA_VERSION}
ARG LINUX_VERSION=centos7
FROM nvidia/cuda:${CUDA_VERSION}-devel-${LINUX_VERSION}

ARG CUDA_MAJORMINOR_VERSION

ARG ARROW_CPP_VERSION=0.12.1
ARG CC_VERSION=5
ARG CXX_VERSION=5
ARG CFFI_VERSION=1.11.5
ARG CMAKE_VERSION=3.14.3
ARG CYTHON_VERSION=0.29.*
ARG DASK_VERSION=1.2.2
ARG DISTRIBUTED_VERSION=1.28.0
ARG FAISSGPU_VERSION=1.5.0
ARG HASH_JOIN=ON
ARG IPYTHON_VERSION=7.3*
ARG LIBGCC_NG_VERSION=7.3.0
ARG LIBGFORTRAIN_NG_VERSION=7.3.0
ARG LIBSTDCXX_NG_VERSION=7.3.0
ARG MINICONDA_URL=https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh
ARG NUMBA_VERSION=0.41
ARG NUMPY_VERSION=1.16.2
ARG NVIDIA_CONDA_LABEL=nvidia/label/cuda${CUDA_MAJORMINOR_VERSION}
ARG RAPIDSAI_CONDA_LABEL=rapidsai/label/cuda${CUDA_MAJORMINOR_VERSION}
ARG RAPIDS_CONDA_VERSION_SPEC=0.7*
ARG PANDAS_VERSION=0.23.4
ARG PYARROW_VERSION=0.12.1
ARG PYTHON_VERSION=3.6
ARG SCIPY_VERSION=1.2.1
ARG SKLEARN_VERSION=0.20.3
ARG TINI_URL=https://github.com/krallin/tini/releases/download/v0.18.0/tini
ARG NUM_BUILD_CPUS=""
ARG UTILS_DIR=utils
ARG SUPPORT_FILES_DIR=supportfiles
ARG RAPIDS_SRC_DIR=/rapids

# Add /usr/local/cuda/* temporarily to LD_LIBRARY_PATH to support various build steps
# This will need to be removed later since it causes problems with certain runtime libs (numba.cuda)
ENV LD_LIBRARY_PATH_POSTBUILD=$LD_LIBRARY_PATH
ENV LD_LIBRARY_PATH=$LD_LIBRARY_PATH_POSTBUILD:/usr/local/cuda/lib64:/usr/local/cuda/lib64/stubs
ENV NUMBAPRO_NVVM=/usr/local/cuda/nvvm/lib64/libnvvm.so
ENV NUMBAPRO_LIBDEVICE=/usr/local/cuda/nvvm/libdevice
ENV PATH=$PATH:/conda/bin
ENV CUDA_VERSION=${CUDA_MAJORMINOR_VERSION}

# devtoolset-7 ENV vars
# devtoolset-7-* packages will need to be seen first, update PATH accordingly
# NOTE: These are commented out since gcc is being built from source
#   If devtoolset-7 is used, uncomment these vars.
# ENV PATH=/opt/rh/devtoolset-7/root/usr/bin:$PATH:/conda/bin
# ENV CC=/opt/rh/devtoolset-7/root/usr/bin/gcc
# ENV CXX=/opt/rh/devtoolset-7/root/usr/bin/g++
# ENV CUDAHOSTCXX=/opt/rh/devtoolset-7/root/usr/bin/g++
RUN mkdir -p ${RAPIDS_SRC_DIR}/tmp
#
# The support dir contains RPMs that enable additional repos needed
# for CentOS (among other things). Copy them to a temp dir and remove
# after installed.
#
COPY ${SUPPORT_FILES_DIR}/*.rpm ${RAPIDS_SRC_DIR}/tmp

RUN yum install -y ${RAPIDS_SRC_DIR}/tmp/*.rpm && \
    yum upgrade -y && \
    yum install -y \
      bzip2 \
      curl \
      git \
      screen \
      vim \
      wget \
      which \
      clang \
      make \
      libnccl-2.4.2-1+cuda${CUDA_MAJORMINOR_VERSION} \
      libnccl-devel-2.4.2-1+cuda${CUDA_MAJORMINOR_VERSION} \
      libnccl-static-2.4.2-1+cuda${CUDA_MAJORMINOR_VERSION} \
      gmp-devel mpfr-devel libmpc-devel file 

RUN curl -L ${TINI_URL} -o /usr/bin/tini && \
    chmod +x /usr/bin/tini

RUN rm -rf ${RAPIDS_SRC_DIR}/tmp
# NOTE: Copying a pre-built gcc7 could be an option to avoid the
# expensive build step.
### COPY gcc7 ${GCC7_DIR}

# Build gcc 7 and set the environment to use it
# NOTE: this step requires packages gmp-devel, mpfr-devel,
# libmpc-devel, and file (see above)

# NOTE: Q: What about devtoolset-7? Will that work instead?
#       A: Not quite:
#          https://stackoverflow.com/questions/49393888/how-can-i-use-the-new-c-11-abi-with-devtoolset-7-on-centos-rhel
#          (tl;dr: devtoolset-7 does not support the new cxx11 ABI since it
#          conflicts with CentOS sys libs.)
#          Rapids will use new new ABI for its binaries, including its own
#          libstdc++, and the rest of CentOS will continue to use the
#          system default libs.

ARG GCC7_DIR=${RAPIDS_SRC_DIR}/gcc7

RUN mkdir -p ${GCC7_DIR}
RUN cd ${GCC7_DIR} && wget -q http://ftp.gnu.org/gnu/gcc/gcc-7.2.0/gcc-7.2.0.tar.gz 
RUN cd ${GCC7_DIR} && tar zxf gcc-7.2.0.tar.gz
RUN cd ${GCC7_DIR}/gcc-7.2.0 && \
    ./configure --prefix=${GCC7_DIR} --disable-multilib && \
    make -j${NUM_BUILD_CPUS} && make install

# Remove gcc source dir and tarfile
RUN rm -r ${GCC7_DIR}/gcc-7.2.0 ${GCC7_DIR}/gcc-7.2.0.tar.gz

# Update environment to use new gcc7
ENV CC=${GCC7_DIR}/bin/gcc
ENV CXX=${GCC7_DIR}/bin/g++
ENV PATH=${GCC7_DIR}/bin:$PATH
ENV CUDAHOSTCXX=${GCC7_DIR}/bin/g++

# Update the current LD_LIBRARY_PATH with the new lib64 dir for
# remaining build steps and LD_LIBRARY_PATH_POSTBUILD for runtime use
# after building the container.
ENV LD_LIBRARY_PATH=${GCC7_DIR}/lib64:$LD_LIBRARY_PATH
ENV LD_LIBRARY_PATH_POSTBUILD=${GCC7_DIR}/lib64:$LD_LIBRARY_PATH_POSTBUILD

# NOTE: Many/all of the package versions used below are defined in the
# "args" insertfile

RUN curl ${MINICONDA_URL} -o /miniconda.sh && \
    sh /miniconda.sh -b -p /conda && \
    conda update -n base conda && \
    rm -f /miniconda.sh

########################################
# conda environment
# NOTE: use these mirrors for faster downloads
#       -c http://10.33.227.188:88/numba \
#       -c http://10.33.227.188:88/conda-forge \
RUN export CUDA_MAJOR=`echo $CUDA_VERSION | cut -d'.' -f1` && \
    export CUDA_MINOR=`echo $CUDA_VERSION | cut -d'.' -f2` && \
    conda create -n rapids python=${PYTHON_VERSION} && \
    conda install -n rapids -y \
      -c ${RAPIDSAI_CONDA_LABEL} \
      -c rapidsai-nightly/label/cuda${CUDA_MAJORMINOR_VERSION} \
      -c ${NVIDIA_CONDA_LABEL} \
      -c numba \
      -c conda-forge \
      -c pytorch \
      -c defaults \
      arrow-cpp=${PYARROW_VERSION} \
      bokeh \
      cffi=${CFFI_VERSION} \
      cmake=${CMAKE_VERSION} \
      cmake_setuptools>=0.1.3 \
      cuda${CUDA_MAJOR}${CUDA_MINOR} \
      cython=${CYTHON_VERSION} \
      dask=${DASK_VERSION} \
      distributed=${DISTRIBUTED_VERSION} \
      faiss-gpu=${FAISSGPU_VERSION} \
      ipython=${IPYTHON_VERSION} \
      jupyterlab \
      openblas \
      matplotlib \
      networkx \
      numba=${NUMBA_VERSION} \
      numpy=${NUMPY_VERSION} \
      nvgraph \
      pandas=${PANDAS_VERSION} \
      pyarrow=${PYARROW_VERSION} \
      pytest \
      scikit-learn \
      scipy \
      seaborn \
    && conda clean -a

# Special case: libcumlmg is not available for CUDA 9.2
RUN if [ "${CUDA_MAJORMINOR_VERSION}" != "9.2" ]; then conda install -n rapids -y --no-deps -c ${NVIDIA_CONDA_LABEL} -c conda-forge libcumlmg; fi

# Enables "source activate conda"
SHELL ["/bin/bash", "-c"]

# Assume the RAPIDS repos have been cloned to the 'rapids' dir.
# (this is done automatically when using 'rapidsdevtool.sh buildDockerImage',
#  see rapidsdevtool.sh help for more details)
# FIXME: FYI, the container build process is now also cloning.
RUN mkdir -p ${RAPIDS_SRC_DIR}
COPY rapids ${RAPIDS_SRC_DIR}
COPY utils ${RAPIDS_SRC_DIR}/${UTILS_DIR}

RUN cd ${RAPIDS_SRC_DIR} && ./clone.sh

# Assume the build.sh script is present.
# (this is done automatically when using 'rapidsdevtool.sh buildDockerImage',
#  see rapidsdevtool.sh help for more details)
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh rmm && \
    cd rmm && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh custrings && \
    cd custrings && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh cudf && \
    cd cudf && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh cuml && \
    cd cuml && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh cugraph && \
    cd cugraph && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh xgboost && \
    cd xgboost && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh dask-xgboost && \
    cd dask-xgboost && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh dask-cudf && \
    cd dask-cudf && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh dask-cuda && \
    cd dask-cuda && git clean -xdff
RUN source activate rapids && cd ${RAPIDS_SRC_DIR} && \
    ./build.sh dask-cuml && \
    cd dask-cuml && git clean -xdff

# Add test file for testing from within the container
COPY ${SUPPORT_FILES_DIR}/test.sh /test.sh

#
# Change LD_LIBRARY_PATH to exclude /usr/local/cuda/* since
# numba.cuda cannot load that, and instead have it load
# /lib64/libcuda.so instead
#
ENV LD_LIBRARY_PATH=${GCC7_DIR}/lib64:$LD_LIBRARY_PATH_ORIG:$CONDA_PREFIX

# Copy notebooks, leave git meta-data, EXPOSE ports, WORKDIR=/rapids/notebooks
# FIXME: RAPIDS notebooks are now cloned in the container during
# container build, but maybe they should be copied instead.
#COPY rapids/notebooks ${RAPIDS_SRC_DIR}/notebooks

WORKDIR /rapids/notebooks
# Jupyter notebook port
EXPOSE 8888
# Dask Scheduler Bokeh port
EXPOSE 8787
EXPOSE 8786

# Automatically active conda env
RUN echo "source activate rapids" > ~/.bashrc

ENTRYPOINT [ "/usr/bin/tini", "--" ]
CMD [ "/bin/bash" ]
